{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tushar-rancy/Decission-Tree-assignment/blob/main/Decision_Tree_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe0c31d",
      "metadata": {
        "id": "8fe0c31d"
      },
      "source": [
        "# Decision Tree – Assignment Q&A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd86576",
      "metadata": {
        "id": "dbd86576"
      },
      "source": [
        "### Q1. What is a Decision Tree, and how does it work"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b22b398",
      "metadata": {
        "id": "9b22b398"
      },
      "source": [
        "**Answer:**\n",
        "A Decision Tree is a flowchart-like structure where each internal node represents a decision on a feature, each branch represents an outcome of the decision, and each leaf node represents a class label or output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6090e2d",
      "metadata": {
        "id": "b6090e2d"
      },
      "source": [
        "### Q2. What are impurity measures in Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78094d3",
      "metadata": {
        "id": "e78094d3"
      },
      "source": [
        "**Answer:**\n",
        "Impurity measures evaluate how mixed the classes are in the data subset. Common measures: Gini Impurity and Entropy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705fa45e",
      "metadata": {
        "id": "705fa45e"
      },
      "source": [
        "### Q3. What is the mathematical formula for Gini Impurity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407f8efd",
      "metadata": {
        "id": "407f8efd"
      },
      "source": [
        "**Answer:**\n",
        "Gini = 1 - ∑ (p_i)² where p_i is the probability of class i."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff8c8298",
      "metadata": {
        "id": "ff8c8298"
      },
      "source": [
        "### Q4. What is the mathematical formula for Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d39cb7",
      "metadata": {
        "id": "57d39cb7"
      },
      "source": [
        "**Answer:**\n",
        "Entropy = - ∑ p_i * log₂(p_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d17436",
      "metadata": {
        "id": "09d17436"
      },
      "source": [
        "### Q5. What is Information Gain, and how is it used in Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e387395",
      "metadata": {
        "id": "4e387395"
      },
      "source": [
        "**Answer:**\n",
        "Information Gain measures the reduction in entropy or Gini after a dataset split. It's used to choose the best feature to split on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f57efb",
      "metadata": {
        "id": "61f57efb"
      },
      "source": [
        "### Q6. What is the difference between Gini Impurity and Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a4951f4",
      "metadata": {
        "id": "4a4951f4"
      },
      "source": [
        "**Answer:**\n",
        "Both are impurity metrics. Entropy involves logarithms and can be slower. Gini is generally faster and often yields similar splits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26fa151",
      "metadata": {
        "id": "b26fa151"
      },
      "source": [
        "### Q7. What is the mathematical explanation behind Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d4646d",
      "metadata": {
        "id": "e4d4646d"
      },
      "source": [
        "**Answer:**\n",
        "They recursively split data based on the feature that provides the best Information Gain or Gini reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2592c5bf",
      "metadata": {
        "id": "2592c5bf"
      },
      "source": [
        "### Q8. What is Pre-Pruning in Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4735eaf4",
      "metadata": {
        "id": "4735eaf4"
      },
      "source": [
        "**Answer:**\n",
        "Pre-Pruning stops the tree from growing when a condition (like max depth or min samples) is met."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9aade55",
      "metadata": {
        "id": "a9aade55"
      },
      "source": [
        "### Q9. What is Post-Pruning in Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b75cb2de",
      "metadata": {
        "id": "b75cb2de"
      },
      "source": [
        "**Answer:**\n",
        "Post-Pruning grows the full tree and then removes branches that do not provide significant gain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0d4bb7",
      "metadata": {
        "id": "3b0d4bb7"
      },
      "source": [
        "### Q10. What is the difference between Pre-Pruning and Post-Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d2e45b",
      "metadata": {
        "id": "44d2e45b"
      },
      "source": [
        "**Answer:**\n",
        "Pre-Pruning halts tree growth early; Post-Pruning removes nodes after a full tree is built."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277ba1f8",
      "metadata": {
        "id": "277ba1f8"
      },
      "source": [
        "### Q11. What is a Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0663689e",
      "metadata": {
        "id": "0663689e"
      },
      "source": [
        "**Answer:**\n",
        "It’s a tree model used for predicting continuous values instead of class labels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93a091b6",
      "metadata": {
        "id": "93a091b6"
      },
      "source": [
        "### Q12. What are the advantages and disadvantages of Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39871023",
      "metadata": {
        "id": "39871023"
      },
      "source": [
        "**Answer:**\n",
        "**Advantages**: Interpretable, no need for feature scaling\n",
        "**Disadvantages**: Prone to overfitting, unstable with small data changes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c59e0bf",
      "metadata": {
        "id": "3c59e0bf"
      },
      "source": [
        "### Q13. How does a Decision Tree handle missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bb2aa1",
      "metadata": {
        "id": "e1bb2aa1"
      },
      "source": [
        "**Answer:**\n",
        "Some implementations can handle them by surrogate splits or ignoring those rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b9d3892",
      "metadata": {
        "id": "8b9d3892"
      },
      "source": [
        "### Q14. How does a Decision Tree handle categorical features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02aef249",
      "metadata": {
        "id": "02aef249"
      },
      "source": [
        "**Answer:**\n",
        "It can split based on categories directly or after encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48580a4e",
      "metadata": {
        "id": "48580a4e"
      },
      "source": [
        "### Q15. What are some real-world applications of Decision Trees?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034b4187",
      "metadata": {
        "id": "034b4187"
      },
      "source": [
        "**Answer:**\n",
        "Loan approval, fraud detection, disease diagnosis, and customer segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e193a2",
      "metadata": {
        "id": "93e193a2"
      },
      "source": [
        "## Practical Implementation of Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4aeb63",
      "metadata": {
        "id": "6b4aeb63"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"your_dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "451b959e",
      "metadata": {
        "id": "451b959e"
      },
      "source": [
        "### Q2. Explore the dataset – check for nulls and datatypes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6a1f8e",
      "metadata": {
        "id": "da6a1f8e"
      },
      "outputs": [],
      "source": [
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa14710",
      "metadata": {
        "id": "2aa14710"
      },
      "source": [
        "### Q3. Split data into features and target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b738f78",
      "metadata": {
        "id": "8b738f78"
      },
      "outputs": [],
      "source": [
        "X = df.drop('target', axis=1)\n",
        "y = df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec930003",
      "metadata": {
        "id": "ec930003"
      },
      "source": [
        "### Q4. Perform train-test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63e0db8",
      "metadata": {
        "id": "f63e0db8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b816aa6",
      "metadata": {
        "id": "2b816aa6"
      },
      "source": [
        "### Q5. Train a Decision Tree Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18283aef",
      "metadata": {
        "id": "18283aef"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4699547e",
      "metadata": {
        "id": "4699547e"
      },
      "source": [
        "### Q6. Evaluate the classifier on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0560dbe",
      "metadata": {
        "id": "a0560dbe"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605e5831",
      "metadata": {
        "id": "605e5831"
      },
      "source": [
        "### Q7. Visualize the trained Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e21fb2d",
      "metadata": {
        "id": "9e21fb2d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plot_tree(clf, filled=True, feature_names=X.columns, class_names=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2845c9",
      "metadata": {
        "id": "4a2845c9"
      },
      "source": [
        "### Q8. Use Gini and Entropy as splitting criteria and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299ec6db",
      "metadata": {
        "id": "299ec6db"
      },
      "outputs": [],
      "source": [
        "clf_gini = DecisionTreeClassifier(criterion='gini')\n",
        "clf_entropy = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "clf_gini.fit(X_train, y_train)\n",
        "clf_entropy.fit(X_train, y_train)\n",
        "\n",
        "print('Gini Accuracy:', accuracy_score(y_test, clf_gini.predict(X_test)))\n",
        "print('Entropy Accuracy:', accuracy_score(y_test, clf_entropy.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10f60d0",
      "metadata": {
        "id": "c10f60d0"
      },
      "source": [
        "### Q9. Implement Pre-Pruning (limit depth and min samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7092d4c1",
      "metadata": {
        "id": "7092d4c1"
      },
      "outputs": [],
      "source": [
        "clf_pruned = DecisionTreeClassifier(max_depth=3, min_samples_split=10)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "print('Pruned Accuracy:', accuracy_score(y_test, clf_pruned.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de16f63",
      "metadata": {
        "id": "3de16f63"
      },
      "source": [
        "### Q10. Train and evaluate a Decision Tree Regressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd61760",
      "metadata": {
        "id": "9cd61760"
      },
      "outputs": [],
      "source": [
        "reg = DecisionTreeRegressor(max_depth=3)\n",
        "reg.fit(X_train, y_train)\n",
        "print('Regressor Score:', reg.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ab93d3",
      "metadata": {
        "id": "25ab93d3"
      },
      "source": [
        "### Q16. Import necessary libraries and load dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62020bf6",
      "metadata": {
        "id": "62020bf6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"your_dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "327e318b",
      "metadata": {
        "id": "327e318b"
      },
      "source": [
        "### Q17. Explore the dataset – check for nulls and datatypes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce6460a",
      "metadata": {
        "id": "4ce6460a"
      },
      "outputs": [],
      "source": [
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c65f2c",
      "metadata": {
        "id": "72c65f2c"
      },
      "source": [
        "### Q18. Split data into features and target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdc265d",
      "metadata": {
        "id": "fbdc265d"
      },
      "outputs": [],
      "source": [
        "X = df.drop('target', axis=1)\n",
        "y = df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d269abc6",
      "metadata": {
        "id": "d269abc6"
      },
      "source": [
        "### Q19. Perform train-test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbc8556",
      "metadata": {
        "id": "acbc8556"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6d7d65",
      "metadata": {
        "id": "de6d7d65"
      },
      "source": [
        "### Q20. Train a Decision Tree Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8698f75f",
      "metadata": {
        "id": "8698f75f"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6206890d",
      "metadata": {
        "id": "6206890d"
      },
      "source": [
        "### Q21. Evaluate the classifier on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a12116f",
      "metadata": {
        "id": "1a12116f"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d79c0009",
      "metadata": {
        "id": "d79c0009"
      },
      "source": [
        "### Q22. Visualize the trained Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2434b54e",
      "metadata": {
        "id": "2434b54e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plot_tree(clf, filled=True, feature_names=X.columns, class_names=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166aa405",
      "metadata": {
        "id": "166aa405"
      },
      "source": [
        "### Q23. Use Gini and Entropy as splitting criteria and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df6ee4f1",
      "metadata": {
        "id": "df6ee4f1"
      },
      "outputs": [],
      "source": [
        "clf_gini = DecisionTreeClassifier(criterion='gini')\n",
        "clf_entropy = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "clf_gini.fit(X_train, y_train)\n",
        "clf_entropy.fit(X_train, y_train)\n",
        "\n",
        "print('Gini Accuracy:', accuracy_score(y_test, clf_gini.predict(X_test)))\n",
        "print('Entropy Accuracy:', accuracy_score(y_test, clf_entropy.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dca1cd9",
      "metadata": {
        "id": "5dca1cd9"
      },
      "source": [
        "### Q24. Implement Pre-Pruning (limit depth and min samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f00f3e",
      "metadata": {
        "id": "59f00f3e"
      },
      "outputs": [],
      "source": [
        "clf_pruned = DecisionTreeClassifier(max_depth=3, min_samples_split=10)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "print('Pruned Accuracy:', accuracy_score(y_test, clf_pruned.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0876f865",
      "metadata": {
        "id": "0876f865"
      },
      "source": [
        "### Q25. Evaluate model performance using accuracy, precision, recall, and F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4eb97f",
      "metadata": {
        "id": "6b4eb97f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "print('Precision:', precision_score(y_test, y_pred, average='binary'))\n",
        "print('Recall:', recall_score(y_test, y_pred, average='binary'))\n",
        "print('F1 Score:', f1_score(y_test, y_pred, average='binary'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8019f684",
      "metadata": {
        "id": "8019f684"
      },
      "source": [
        "### Q26. Plot feature importance from Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a63cbc",
      "metadata": {
        "id": "56a63cbc"
      },
      "outputs": [],
      "source": [
        "importances = clf.feature_importances_\n",
        "features = X.columns\n",
        "sns.barplot(x=importances, y=features)\n",
        "plt.title('Feature Importances')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62514152",
      "metadata": {
        "id": "62514152"
      },
      "source": [
        "### Q27. Export the Decision Tree as a DOT file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a31998c2",
      "metadata": {
        "id": "a31998c2"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(clf, out_file='tree.dot', feature_names=X.columns, class_names=True, filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d42866a",
      "metadata": {
        "id": "6d42866a"
      },
      "source": [
        "### Q28. Train and evaluate a Decision Tree Regressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed64194",
      "metadata": {
        "id": "8ed64194"
      },
      "outputs": [],
      "source": [
        "reg = DecisionTreeRegressor(max_depth=3)\n",
        "reg.fit(X_train, y_train)\n",
        "print('Regressor Score:', reg.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd21c3c",
      "metadata": {
        "id": "bdd21c3c"
      },
      "source": [
        "### Q29. Visualize the regression tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62793f99",
      "metadata": {
        "id": "62793f99"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plot_tree(reg, filled=True, feature_names=X.columns)\n",
        "plt.title('Regression Tree')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "448ec28b",
      "metadata": {
        "id": "448ec28b"
      },
      "source": [
        "### Q30. Save and load a trained Decision Tree model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f298d2",
      "metadata": {
        "id": "c6f298d2"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(clf, 'decision_tree_model.pkl')\n",
        "loaded_model = joblib.load('decision_tree_model.pkl')\n",
        "print('Loaded model score:', loaded_model.score(X_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}